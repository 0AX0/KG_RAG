{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e77839",
   "metadata": {},
   "source": [
    "## Useful points:\n",
    "#### Ref: https://platform.openai.com/docs/models/model-endpoint-compatibility\n",
    "| ENDPOINT | LATEST MODELS |\n",
    "| --- | --- |\n",
    "| /v1/audio/transcriptions | whisper-1 |\n",
    "| /v1/audio/translations | whisper-1 |\n",
    "| /v1/chat/completions | gpt-4, gpt-4-0613, gpt-4-32k, gpt-4-32k-0613, gpt-3.5-turbo, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k, gpt-3.5-turbo-16k-0613 |\n",
    "| /v1/completions (Legacy) | gpt-3.5-turbo-instruct, babbage-002, davinci-002 |\n",
    "| /v1/embeddings | text-embedding-ada-002 |\n",
    "| /v1/fine_tuning/jobs | gpt-3.5-turbo, babbage-002, davinci-002 |\n",
    "| /v1/moderations | text-moderation-stable, text-moderation-latest |\n",
    "\n",
    "\n",
    "\n",
    "**From Versa README.md**\n",
    "\n",
    "completions_deployments = [ 'text-curie-001',  'text-davinci-003', 'code-davinci-002']\n",
    "embeddings_deployments = [ 'text-similarity-curie-001', 'text-embedding-ada-002',]\n",
    "chat_deployments = [('gpt-35-turbo', 'gpt-35-turbo'), \n",
    "                    ('gpt-4', 'gpt-4'),\n",
    "                    ('gpt-35-turbo-16K', 'gpt-35-turbo-16K'), \n",
    "                    ('gpt-4-32K', 'gpt-4-32K'),\n",
    "                   ]  # chat consists of tuples of (deployment, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04518bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a822d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.path.join(os.path.expanduser('~'), '.gpt_config.env'))\n",
    "API_KEY = os.environ.get('API_KEY')\n",
    "API_VERSION = os.environ.get('API_VERSION')\n",
    "RESOURCE_ENDPOINT = os.environ.get('RESOURCE_ENDPOINT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b17f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = API_VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d761480",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_deployment_id = 'gpt-4'\n",
    "chat_model_id = chat_deployment_id\n",
    "\n",
    "temperature = 0\n",
    "\n",
    "system_prompt = \"You are an expert biomedical researcher. Answer the Question at the end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "01f5e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "Following sentence is taken from the bioasq dataset (url is http://participants-area.bioasq.org/Tasks/2b/trainingDataset/). Sentence is incomplete, so complete the sentence. Give 5 completion suggestions.\n",
    "\"Which acetylcholinesterase inhibitors are used \"\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "What genes are associated with Leiomyi\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5f99cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.72 ms, sys: 3.19 ms, total: 12.9 ms\n",
      "Wall time: 5.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    temperature=temperature, \n",
    "    deployment_id=chat_deployment_id,\n",
    "    model=chat_model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": instruction}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "40a70ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Which acetylcholinesterase inhibitors are used in the treatment of Alzheimer's disease?\"\n",
      "2. \"Which acetylcholinesterase inhibitors are used to manage symptoms of myasthenia gravis?\"\n",
      "3. \"Which acetylcholinesterase inhibitors are used in the treatment of glaucoma?\"\n",
      "4. \"Which acetylcholinesterase inhibitors are used to counteract the effects of nerve gas?\"\n",
      "5. \"Which acetylcholinesterase inhibitors are used in the management of Parkinson's disease?\"\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09b1a988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 ms, sys: 4.78 ms, total: 40.1 ms\n",
      "Wall time: 831 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# completion = openai.Completion.create(\n",
    "#     temperature=temperature,  \n",
    "#     deployment_id=\"text-curie-001\",\n",
    "#     model=\"text-curie-001\",\n",
    "#     prompt=\"What is the capital of France?\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d738efd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Diseases\": [\"multiple sclerosis\"]}\n"
     ]
    }
   ],
   "source": [
    "chat_deployment_id = 'gpt-35-turbo'\n",
    "chat_model_id = 'gpt-35-turbo'\n",
    "temperature = 0\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert disease entity extractor from a sentence and report it as JSON in the following format:\n",
    "{{Diseases : <List of extracted entities>}}\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "Genes assciated with multiple sclerosis?\n",
    "\"\"\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    temperature=temperature, \n",
    "    top_p=1,\n",
    "    deployment_id=chat_deployment_id,\n",
    "    model=chat_model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": instruction}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015fe55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
