{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d36ba466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7cf4da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_auc(test_question):\n",
    "    label_encoder = LabelEncoder()\n",
    "    test_question['label_encoded'] = label_encoder.fit_transform(test_question['label'])\n",
    "    test_question['extracted_answer_encoded'] = label_encoder.transform(test_question['extracted_answer'])\n",
    "    auc_score = roc_auc_score(test_question['label_encoded'], test_question['extracted_answer_encoded'])\n",
    "    return auc_score\n",
    "\n",
    "def extract_answer(text):\n",
    "    pattern = r\"(True|False|Don't know)\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3e745d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_PATH = \"../../../data/analysis_results/Llama_2_13b_chat_hf_rag_based_response.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "ed2878a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>extracted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enhanced S-cone syndrome is not a vitreoretina...</td>\n",
       "      <td>False</td>\n",
       "      <td>Based on the information provided, the answe...</td>\n",
       "      <td>Don't know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metronidazole treats crohn's disease</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"answer\": True\\n}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KLEEFSTRA SYNDROME 1 is not associated with Ge...</td>\n",
       "      <td>False</td>\n",
       "      <td>Based on the information provided, the answe...</td>\n",
       "      <td>Don't know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STARGARDT DISEASE 1 (disorder) is not associat...</td>\n",
       "      <td>False</td>\n",
       "      <td>Based on the information provided, the answe...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juvenile polyposis syndrome associates Gene SMAD4</td>\n",
       "      <td>True</td>\n",
       "      <td>Based on the information provided, the answe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  label  \\\n",
       "0  enhanced S-cone syndrome is not a vitreoretina...  False   \n",
       "1               metronidazole treats crohn's disease   True   \n",
       "2  KLEEFSTRA SYNDROME 1 is not associated with Ge...  False   \n",
       "3  STARGARDT DISEASE 1 (disorder) is not associat...  False   \n",
       "4  Juvenile polyposis syndrome associates Gene SMAD4   True   \n",
       "\n",
       "                                          llm_answer extracted_answer  \n",
       "0    Based on the information provided, the answe...       Don't know  \n",
       "1                               {\\n\"answer\": True\\n}             True  \n",
       "2    Based on the information provided, the answe...       Don't know  \n",
       "3    Based on the information provided, the answe...            False  \n",
       "4    Based on the information provided, the answe...             True  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_df = pd.read_csv(RESPONSE_PATH)\n",
    "\n",
    "response_df.loc[:, 'extracted_answer'] = response_df['llm_answer'].apply(extract_answer)\n",
    "response_df.loc[:, \"answer_count\"] = response_df.extracted_answer.apply(lambda x:len(x))\n",
    "\n",
    "response_df_multiple_answers = response_df[response_df.answer_count > 1]\n",
    "response_df_single_answer = response_df.drop(response_df_multiple_answers.index)\n",
    "response_df_single_answer.drop(\"answer_count\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "response_df_multiple_answers_ = []\n",
    "for index, row in response_df_multiple_answers.iterrows():\n",
    "    if row[\"extracted_answer\"][0] == row[\"extracted_answer\"][1]:\n",
    "        response_df_multiple_answers_.append((row[\"question\"], row[\"label\"], row[\"llm_answer\"], row[\"extracted_answer\"][0]))\n",
    "    else:\n",
    "        response_df_multiple_answers_.append((row[\"question\"], row[\"label\"], row[\"llm_answer\"], \"Don't know\"))\n",
    "\n",
    "response_df_multiple_answers_ = pd.DataFrame(response_df_multiple_answers_, columns=[\"question\", \"label\", \"llm_answer\", \"extracted_answer\"])\n",
    "\n",
    "response_df_final = pd.concat([response_df_single_answer, response_df_multiple_answers_], ignore_index=True)\n",
    "response_df_final = response_df_final.explode(\"extracted_answer\")\n",
    "response_df_final['extracted_answer'].fillna(\"Don't know\", inplace=True)\n",
    "response_df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "26fdd7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_18664/3470548911.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  response_df_certain_response.extracted_answer = response_df_certain_response.extracted_answer.apply(lambda x:response_transform[x])\n"
     ]
    }
   ],
   "source": [
    "response_df_uncertain_response = response_df_final[response_df_final.extracted_answer == \"Don't know\"]\n",
    "response_df_certain_response = response_df_final[response_df_final.extracted_answer != \"Don't know\"]\n",
    "# response_df_certain_response.loc[:, \"extracted_answer\"] = response_df_certain_response.extracted_answer.astype(bool)\n",
    "\n",
    "\n",
    "response_transform = {\n",
    "    \"True\" : True,\n",
    "    \"False\" : False\n",
    "}\n",
    "\n",
    "response_df_certain_response.extracted_answer = response_df_certain_response.extracted_answer.apply(lambda x:response_transform[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "24dddc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True response =  0.9196940726577438\n",
      "False response =  0.08030592734225621\n",
      "Uncertainty =  0.1412151067323481\n"
     ]
    }
   ],
   "source": [
    "total_certain_response = response_df_certain_response.shape[0]\n",
    "total_uncertain_response = response_df_uncertain_response.shape[0]\n",
    "total_response = response_df_final.shape[0]\n",
    "\n",
    "correct_response = response_df_certain_response[response_df_certain_response.label == response_df_certain_response.extracted_answer].shape[0]\n",
    "incorrect_response = response_df_certain_response[response_df_certain_response.label != response_df_certain_response.extracted_answer].shape[0]\n",
    "\n",
    "true_response = correct_response/total_certain_response\n",
    "false_response = incorrect_response/total_certain_response\n",
    "uncertainty = total_uncertain_response/total_response\n",
    "\n",
    "\n",
    "print(\"True response = \",true_response)\n",
    "print(\"False response = \",false_response)\n",
    "print(\"Uncertainty = \",uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d134bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9802876738402566e-42 0.568678020365512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_18664/1277173120.py:6: DeprecationWarning: 'binom_test' is deprecated in favour of 'binomtest' from version 1.7.0 and will be removed in Scipy 1.12.0.\n",
      "  p_value = binom_test(x, N, p=p, alternative='greater')\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "N = response_df_certain_response.shape[0]\n",
    "x = correct_response\n",
    "p = response_df_certain_response[response_df_certain_response.label==True].shape[0]/N\n",
    "p_value = binom_test(x, N, p=p, alternative='greater') \n",
    "p_value\n",
    "\n",
    "H = np.divide(false_response, uncertainty)\n",
    "print(p_value, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ee929f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True response =  0.8988195615514334\n",
      "False response =  0.10118043844856661\n",
      "Uncertainty =  0.026272577996715927\n"
     ]
    }
   ],
   "source": [
    "total_certain_response = response_df_certain_response.shape[0]\n",
    "total_uncertain_response = response_df_uncertain_response.shape[0]\n",
    "total_response = response_df_final.shape[0]\n",
    "\n",
    "correct_response = response_df_certain_response[response_df_certain_response.label == response_df_certain_response.extracted_answer].shape[0]\n",
    "incorrect_response = response_df_certain_response[response_df_certain_response.label != response_df_certain_response.extracted_answer].shape[0]\n",
    "\n",
    "true_response = correct_response/total_certain_response\n",
    "false_response = incorrect_response/total_certain_response\n",
    "uncertainty = total_uncertain_response/total_response\n",
    "\n",
    "\n",
    "print(\"True response = \",true_response)\n",
    "print(\"False response = \",false_response)\n",
    "print(\"Uncertainty = \",uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6d1f34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score =  0.8829975227085054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_18664/4016225422.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_question['label_encoded'] = label_encoder.fit_transform(test_question['label'])\n",
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_18664/4016225422.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_question['extracted_answer_encoded'] = label_encoder.transform(test_question['extracted_answer'])\n"
     ]
    }
   ],
   "source": [
    "auc_score = get_auc(response_df_certain_response)\n",
    "print(\"AUC score = \", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cd33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
