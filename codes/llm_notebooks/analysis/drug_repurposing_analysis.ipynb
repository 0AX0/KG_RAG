{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6eb0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from neo4j import GraphDatabase, basic_auth\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "from scipy.stats import sem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0718f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1) + len(set2) - intersection    \n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        jaccard_similarity = intersection / union\n",
    "        return jaccard_similarity\n",
    "    \n",
    "def extract_answer(text):\n",
    "    pattern = r'{[^{}]*}'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def extract_by_splitting(text):\n",
    "    compound_list = text.split(':')[1].split(\"Diseases\")[0].split(\"], \")[0]+\"]\"\n",
    "    disease_list = text.split(':')[-1].split(\"}\")[0]\n",
    "    resp = {}\n",
    "    resp[\"Compounds\"] = ast.literal_eval(compound_list)\n",
    "    resp[\"Diseases\"] = ast.literal_eval(disease_list)\n",
    "    return resp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec8211d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_PATH = \"../../../data/analysis_results/\"\n",
    "\n",
    "FILES = [\n",
    "    \"Llama_2_13b_chat_hf_entity_recognition_based_node_retrieval_rag_based_drug_repurposing_questions_response.csv\",\n",
    "    \"gpt_35_turbo_entity_recognition_based_node_retrieval_rag_based_drug_repurposing_questions_response.csv\",\n",
    "    \"gpt_4_entity_recognition_based_node_retrieval_rag_based_drug_repurposing_questions_response.csv\"\n",
    "]\n",
    "\n",
    "MODEL_LIST = [\"Llama-13b\", \"GPT-3.5-Turbo\", \"GPT-4\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01e358b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '{' (<unknown>, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[1;32mIn[59], line 21\u001b[0m\n    llm_answer = json.loads(join_string + ']}')\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/lib/python3.10/json/__init__.py:346\u001b[0m in \u001b[1;35mloads\u001b[0m\n    return _default_decoder.decode(s)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/lib/python3.10/json/decoder.py:337\u001b[0m in \u001b[1;35mdecode\u001b[0m\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/lib/python3.10/json/decoder.py:355\u001b[0;36m in \u001b[0;35mraw_decode\u001b[0;36m\n\u001b[0;31m    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\u001b[0;36m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m\u001b[0;31m:\u001b[0m Expecting value\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3460\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[59], line 23\u001b[0m\n    llm_answer = extract_by_splitting(row[\"llm_answer\"])\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[50], line 24\u001b[0m in \u001b[1;35mextract_by_splitting\u001b[0m\n    resp[\"Compounds\"] = ast.literal_eval(compound_list)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/lib/python3.10/ast.py:64\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/lib/python3.10/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:3\u001b[0;36m\u001b[0m\n\u001b[0;31m    {Compounds]\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '{'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = FILES\n",
    "\n",
    "llm_performance_list = []\n",
    "llm_performance_list_metric = []\n",
    "for file_index, file in tqdm(enumerate(files)):\n",
    "    df = pd.read_csv(os.path.join(PARENT_PATH, file))\n",
    "    df.dropna(subset=[\"llm_answer\"], inplace=True)\n",
    "    llm_performance_list_across_questions = []\n",
    "    for index, row in df.iterrows():\n",
    "        cmp_gt = ast.literal_eval(row[\"compound_groundTruth\"])\n",
    "        disease_gt = ast.literal_eval(row[\"disease_groundTruth\"])\n",
    "        try:\n",
    "            llm_answer = json.loads(extract_answer(row[\"llm_answer\"]))\n",
    "        except:\n",
    "            try:\n",
    "                llm_answer = json.loads(row.llm_answer + '\"]}')\n",
    "            except:\n",
    "                try:\n",
    "                    split_string = row.llm_answer.rsplit(',', 1)\n",
    "                    join_string = split_string[0] + split_string[1]\n",
    "                    llm_answer = json.loads(join_string + ']}')\n",
    "                except:\n",
    "                    llm_answer = extract_by_splitting(row[\"llm_answer\"])\n",
    "        cmp_llm = llm_answer[\"Compounds\"]\n",
    "        disease_llm = llm_answer[\"Diseases\"]\n",
    "        cmp_similarity = jaccard_similarity(cmp_gt, cmp_llm)\n",
    "        disease_similarity = jaccard_similarity(disease_gt, disease_llm)\n",
    "        llm_performance = np.mean([cmp_similarity, disease_similarity])\n",
    "        llm_performance_list_across_questions.append(llm_performance)\n",
    "    llm_performance_list.append(llm_performance_list_across_questions)\n",
    "    llm_performance_list_metric.append((np.mean(llm_performance_list_across_questions), np.std(llm_performance_list_across_questions), sem(llm_performance_list_across_questions), MODEL_LIST[file_index]))\n",
    "drug_repurpose_perf = pd.DataFrame(llm_performance_list_metric, columns=[\"performance_mean\", \"performance_std\", \"performance_sem\", \"model_name\"])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d516d3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>performance_mean</th>\n",
       "      <th>performance_std</th>\n",
       "      <th>performance_sem</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.550097</td>\n",
       "      <td>0.176328</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>GPT-3.5-Turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.621062</td>\n",
       "      <td>0.200532</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>GPT-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   performance_mean  performance_std  performance_sem     model_name\n",
       "0          0.550097         0.176328         0.021542  GPT-3.5-Turbo\n",
       "1          0.621062         0.200532         0.024499          GPT-4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_repurpose_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fa01716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  As an expert biomedical researcher, based on the provided context, I can provide the following answer:\\n\\n{Compounds: [1-(Dimethylamino)-2-methylpropan-2-yl] 2-hydroxy-2,2-diphenylacetate, Methylhomatropine, Drotaverine, Methylatropine, Oxyphencyclimine, Otilonium, Oxyphenonium, Fenoverine, Diphemanil, Mebeverine, Metoclopramide, Mepenzolate, Cinitapride, Mosapride, Itopride, Propulsid, Cimetropium, Dicyclomine, Imipramine, Tridihexethyl, Tiropramide, Alosetron, Atropine, Phloroglucinol, Pipenzolate, Dexmedetomidine, Isopropamide, Isometheptene, Trimebutine, Methantheline, Ciprofloxacin, Butylscopolamine, BELLADONNA, Hexocyclium, Glycopyrronium bromide, Pinaverium, Alverine, Foscarnet, Domperidone, Clidinium, ZINC ion, ANXA11, CHRNA1, CHRNA3, CYP27A1, HOXB1, REPS1, MYORG, DNAH5, PELVIC PAIN, DYSPEPSIA, CHRND, SOX4, SLC10A2, CAMK2B, PLXND1, MED17, HFE, CAMK2A, POLR1D, SOX3, H3-3B, POLR3A, SLC2A3, HSPA9, PHGDH, MRPS25, ARSL, ECM1, SLC46A1, CARMIL2, RPL35A, RYR1, IDS, POLR3B, PHKA2, HLA-B, TYMS, ROR2, ANTXR2, Fibrin},\\n\\nDiseases:'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.llm_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f8f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
