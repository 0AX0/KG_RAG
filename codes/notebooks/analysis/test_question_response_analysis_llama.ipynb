{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d36ba466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7cf4da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_auc(test_question):\n",
    "    label_encoder = LabelEncoder()\n",
    "    test_question['label_encoded'] = label_encoder.fit_transform(test_question['label'])\n",
    "    test_question['extracted_answer_encoded'] = label_encoder.transform(test_question['extracted_answer'])\n",
    "    auc_score = roc_auc_score(test_question['label_encoded'], test_question['extracted_answer_encoded'])\n",
    "    return auc_score\n",
    "\n",
    "def extract_answer(text):\n",
    "    pattern = r\"(True|False|Don't know)\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e745d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPONSE_PATH = \"../../../data/analysis_results/Llama_2_13b_chat_hf_node_retrieval_rag_based_response.csv\"\n",
    "\n",
    "RESPONSE_PATH = \"../../../data/analysis_results/Llama_2_13b_chat_hf_prompt_based_response.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed2878a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>extracted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enhanced S-cone syndrome is not a vitreoretina...</td>\n",
       "      <td>False</td>\n",
       "      <td>{\\n\"answer\": \"False\"\\n}\\n\\nEnhanced S-cone s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metronidazole treats crohn's disease</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"answer\": \"False\"\\n}\\n\\nMetronidazole is ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KLEEFSTRA SYNDROME 1 is not associated with Ge...</td>\n",
       "      <td>False</td>\n",
       "      <td>{\\n  \"answer\": \"False\"\\n}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STARGARDT DISEASE 1 (disorder) is not associat...</td>\n",
       "      <td>False</td>\n",
       "      <td>{\\n  \"answer\": \"False\"\\n}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glycogen storage disease type II associates Ge...</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"answer\": \"True\"\\n}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  label  \\\n",
       "0  enhanced S-cone syndrome is not a vitreoretina...  False   \n",
       "1               metronidazole treats crohn's disease   True   \n",
       "2  KLEEFSTRA SYNDROME 1 is not associated with Ge...  False   \n",
       "3  STARGARDT DISEASE 1 (disorder) is not associat...  False   \n",
       "4  Glycogen storage disease type II associates Ge...   True   \n",
       "\n",
       "                                          llm_answer extracted_answer  \n",
       "0    {\\n\"answer\": \"False\"\\n}\\n\\nEnhanced S-cone s...            False  \n",
       "1    {\\n\"answer\": \"False\"\\n}\\n\\nMetronidazole is ...            False  \n",
       "2                          {\\n  \"answer\": \"False\"\\n}            False  \n",
       "3                          {\\n  \"answer\": \"False\"\\n}            False  \n",
       "4                             {\\n\"answer\": \"True\"\\n}             True  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_df = pd.read_csv(RESPONSE_PATH)\n",
    "\n",
    "response_df.loc[:, 'extracted_answer'] = response_df['llm_answer'].apply(extract_answer)\n",
    "response_df.loc[:, \"answer_count\"] = response_df.extracted_answer.apply(lambda x:len(x))\n",
    "\n",
    "response_df_multiple_answers = response_df[response_df.answer_count > 1]\n",
    "response_df_single_answer = response_df.drop(response_df_multiple_answers.index)\n",
    "response_df_single_answer.drop(\"answer_count\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "response_df_multiple_answers_ = []\n",
    "for index, row in response_df_multiple_answers.iterrows():\n",
    "    if row[\"extracted_answer\"][0] == row[\"extracted_answer\"][1]:\n",
    "        response_df_multiple_answers_.append((row[\"question\"], row[\"label\"], row[\"llm_answer\"], row[\"extracted_answer\"][0]))\n",
    "    else:\n",
    "        response_df_multiple_answers_.append((row[\"question\"], row[\"label\"], row[\"llm_answer\"], \"Don't know\"))\n",
    "\n",
    "response_df_multiple_answers_ = pd.DataFrame(response_df_multiple_answers_, columns=[\"question\", \"label\", \"llm_answer\", \"extracted_answer\"])\n",
    "\n",
    "response_df_final = pd.concat([response_df_single_answer, response_df_multiple_answers_], ignore_index=True)\n",
    "response_df_final = response_df_final.explode(\"extracted_answer\")\n",
    "response_df_final['extracted_answer'].fillna(\"Don't know\", inplace=True)\n",
    "response_df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "26fdd7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_79356/3470548911.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  response_df_certain_response.extracted_answer = response_df_certain_response.extracted_answer.apply(lambda x:response_transform[x])\n"
     ]
    }
   ],
   "source": [
    "response_df_uncertain_response = response_df_final[response_df_final.extracted_answer == \"Don't know\"]\n",
    "response_df_certain_response = response_df_final[response_df_final.extracted_answer != \"Don't know\"]\n",
    "# response_df_certain_response.loc[:, \"extracted_answer\"] = response_df_certain_response.extracted_answer.astype(bool)\n",
    "\n",
    "\n",
    "response_transform = {\n",
    "    \"True\" : True,\n",
    "    \"False\" : False\n",
    "}\n",
    "\n",
    "response_df_certain_response.extracted_answer = response_df_certain_response.extracted_answer.apply(lambda x:response_transform[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ee269fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct response =  0.8669950738916257\n",
      "Incorrect response =  0.12315270935960591\n",
      "Uncertainty =  0.009852216748768473\n"
     ]
    }
   ],
   "source": [
    "total_certain_response = response_df_certain_response.shape[0]\n",
    "total_uncertain_response = response_df_uncertain_response.shape[0]\n",
    "total_response = response_df_final.shape[0]\n",
    "\n",
    "correct_response = response_df_certain_response[response_df_certain_response.label == response_df_certain_response.extracted_answer].shape[0]\n",
    "incorrect_response = response_df_certain_response[response_df_certain_response.label != response_df_certain_response.extracted_answer].shape[0]\n",
    "\n",
    "correct_response_ = correct_response/total_response\n",
    "incorrect_response_ = incorrect_response/total_response\n",
    "uncertainty = total_uncertain_response/total_response\n",
    "\n",
    "\n",
    "print(\"Correct response = \",correct_response_)\n",
    "print(\"Incorrect response = \",incorrect_response_)\n",
    "print(\"Uncertainty = \",uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f63946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct response =  0.8768472906403941\n",
      "Incorrect response =  0.10673234811165845\n",
      "Uncertainty =  0.016420361247947456\n"
     ]
    }
   ],
   "source": [
    "total_certain_response = response_df_certain_response.shape[0]\n",
    "total_uncertain_response = response_df_uncertain_response.shape[0]\n",
    "total_response = response_df_final.shape[0]\n",
    "\n",
    "correct_response = response_df_certain_response[response_df_certain_response.label == response_df_certain_response.extracted_answer].shape[0]\n",
    "incorrect_response = response_df_certain_response[response_df_certain_response.label != response_df_certain_response.extracted_answer].shape[0]\n",
    "\n",
    "correct_response_ = correct_response/total_response\n",
    "incorrect_response_ = incorrect_response/total_response\n",
    "uncertainty = total_uncertain_response/total_response\n",
    "\n",
    "\n",
    "print(\"Correct response = \",correct_response_)\n",
    "print(\"Incorrect response = \",incorrect_response_)\n",
    "print(\"Uncertainty = \",uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24dddc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct response =  0.8669950738916257\n",
      "Incorrect response =  0.12146422628951747\n",
      "Uncertainty =  0.013136288998357963\n"
     ]
    }
   ],
   "source": [
    "total_certain_response = response_df_certain_response.shape[0]\n",
    "total_uncertain_response = response_df_uncertain_response.shape[0]\n",
    "total_response = response_df_final.shape[0]\n",
    "\n",
    "correct_response = response_df_certain_response[response_df_certain_response.label == response_df_certain_response.extracted_answer].shape[0]\n",
    "incorrect_response = response_df_certain_response[response_df_certain_response.label != response_df_certain_response.extracted_answer].shape[0]\n",
    "\n",
    "correct_response_ = correct_response/total_response\n",
    "incorrect_response_ = incorrect_response/total_certain_response\n",
    "uncertainty = total_uncertain_response/total_response\n",
    "\n",
    "\n",
    "print(\"Correct response = \",correct_response_)\n",
    "print(\"Incorrect response = \",incorrect_response_)\n",
    "print(\"Uncertainty = \",uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d38b559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.487249606902626e-35 12.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_79356/3171889519.py:6: DeprecationWarning: 'binom_test' is deprecated in favour of 'binomtest' from version 1.7.0 and will be removed in Scipy 1.12.0.\n",
      "  p_value = binom_test(x, N, p=p, alternative='greater')\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "N = response_df_certain_response.shape[0]\n",
    "x = correct_response\n",
    "p = response_df_certain_response[response_df_certain_response.label==True].shape[0]/N\n",
    "p_value = binom_test(x, N, p=p, alternative='greater') \n",
    "p_value\n",
    "\n",
    "H = np.divide(incorrect_response, total_uncertain_response)\n",
    "print(p_value, H)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d134bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.657548241650208e-44 3.8511804384485666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_79356/1277173120.py:6: DeprecationWarning: 'binom_test' is deprecated in favour of 'binomtest' from version 1.7.0 and will be removed in Scipy 1.12.0.\n",
      "  p_value = binom_test(x, N, p=p, alternative='greater')\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "N = response_df_certain_response.shape[0]\n",
    "x = correct_response\n",
    "p = response_df_certain_response[response_df_certain_response.label==True].shape[0]/N\n",
    "p_value = binom_test(x, N, p=p, alternative='greater') \n",
    "p_value\n",
    "\n",
    "H = np.divide(false_response, uncertainty)\n",
    "print(p_value, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ee929f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True response =  0.8988195615514334\n",
      "False response =  0.10118043844856661\n",
      "Uncertainty =  0.026272577996715927\n"
     ]
    }
   ],
   "source": [
    "total_certain_response = response_df_certain_response.shape[0]\n",
    "total_uncertain_response = response_df_uncertain_response.shape[0]\n",
    "total_response = response_df_final.shape[0]\n",
    "\n",
    "correct_response = response_df_certain_response[response_df_certain_response.label == response_df_certain_response.extracted_answer].shape[0]\n",
    "incorrect_response = response_df_certain_response[response_df_certain_response.label != response_df_certain_response.extracted_answer].shape[0]\n",
    "\n",
    "true_response = correct_response/total_certain_response\n",
    "false_response = incorrect_response/total_certain_response\n",
    "uncertainty = total_uncertain_response/total_response\n",
    "\n",
    "\n",
    "print(\"True response = \",true_response)\n",
    "print(\"False response = \",false_response)\n",
    "print(\"Uncertainty = \",uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6d1f34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score =  0.8829975227085054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_18664/4016225422.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_question['label_encoded'] = label_encoder.fit_transform(test_question['label'])\n",
      "/var/folders/p1/h56gxdhs5vgb0ztp7h4z606h0000gn/T/ipykernel_18664/4016225422.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_question['extracted_answer_encoded'] = label_encoder.transform(test_question['extracted_answer'])\n"
     ]
    }
   ],
   "source": [
    "auc_score = get_auc(response_df_certain_response)\n",
    "print(\"AUC score = \", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cd33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
